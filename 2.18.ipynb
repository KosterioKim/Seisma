{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:36:53.931586200Z",
     "start_time": "2025-03-04T04:36:53.926693400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "import os\n",
    "import tempfile\n",
    "from typing import List\n",
    "import xtgeo\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "import logging\n",
    "import pandas as pd\n",
    "from vtk import vtkCellArray, vtkExplicitStructuredGrid, vtkPoints, reference, vtkCellCenters, vtkPolyData, vtkDoubleArray, vtkIdList, vtkGenericCell, vtkCellLocator\n",
    "from vtkmodules.util.numpy_support import numpy_to_vtkIdTypeArray, numpy_to_vtk,vtk_to_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seismic_ascii_parser(file_path):\n",
    "    all_data = []\n",
    "    head = \"\"\n",
    "    xarray = []\n",
    "    yarray = []\n",
    "    zarray = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            if '#' in line:\n",
    "                head += line\n",
    "                continue\n",
    "            l = line.split(' ')\n",
    "            xarray.append(float(l[0]))\n",
    "            yarray.append(float(l[1]))\n",
    "            zarray.append(float(l[2]))\n",
    "\n",
    "    df = pd.DataFrame({'x': xarray, 'y': yarray, 'z': zarray})\n",
    "    all_data.append({\"test\": df})\n",
    "    return create_seismic_ascii_date(all_data)[0]\n",
    "\n",
    "def create_seismic_ascii_date(data_frame):\n",
    "    for dataframe_data in data_frame:\n",
    "        _, value = next(iter(dataframe_data.items()))\n",
    "        return value.to_dict(\"records\"),\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:36:54.919701900Z",
     "start_time": "2025-03-04T04:36:54.912725100Z"
    }
   },
   "id": "90f743e7f8fda4c5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cube_grid_parser(data_folder: str,\n",
    "                     input_files: List[str]):\n",
    "    \"\"\"\n",
    "    Преобразует файл с содержанием COORD, ZCORN, ACTNUM (сетка куба) в словарь.\n",
    "    :param data_folder: Путь к папке с данными.\n",
    "    :param input_files: Список файлов, поддерживаемых форматом.\n",
    "    :param parameters: Список параметров в виде {имя параметра: значение}, необходимых ридеру для чтения файлов.\n",
    "    :param primary_data: Список мнемоник.\n",
    "    \"\"\"\n",
    "    check_mas = [\"COORD\", \"ZCORN\", \"ACTNUM\", \"SPECGRID\", \"COORDSYS\"]\n",
    "    errors = {\"read_grid\": \"\"}\n",
    "    errors_counter = 1\n",
    "    if len(input_files) > 1:\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".grdecl\", delete=False) as temp_file:\n",
    "            full_path = temp_file.name\n",
    "            with open(full_path, 'w') as f_out:\n",
    "                for file in input_files:\n",
    "                    with open(os.path.join(data_folder, file), 'r') as f:\n",
    "                        data = remove_comment_lines(f.read()).replace(\"NOECHO\",\"\").replace(\"ECHO\",\"\")\n",
    "                        f_out.write(data)\n",
    "                        f_out.write(\"\\n\")\n",
    "    else:\n",
    "        full_path = os.path.join(data_folder, input_files[0])\n",
    "\n",
    "    _, keys = find_key(full_path)\n",
    "    for key in check_mas:\n",
    "        if key not in keys:\n",
    "            errors[\"read_grid\"] += f\"{errors_counter}) Отсутвует ключ {key}, дозагрузите нужный файл\\n\"\n",
    "            errors_counter+=1\n",
    "\n",
    "    if errors_counter > 1:\n",
    "        return {}, errors\n",
    "\n",
    "    grid = xtgeo.grid_from_file(full_path, fformat=\"grdecl\")\n",
    "\n",
    "    res = np.all((grid.actnum_array >= 0) & (grid.actnum_array <= 1))\n",
    "    if not res:\n",
    "        errors[\"read_grid\"] += f\"{errors_counter}) Значение ACTNUM не входит в диапазон от 0 до 1\"\n",
    "        errors_counter += 1\n",
    "        return {}, errors\n",
    "    i_max = grid.ncol\n",
    "    j_max = grid.nrow\n",
    "    k_max = grid.nlay\n",
    "    #grid_idx = (np.arange(i_max * j_max * k_max)\n",
    "    #            .reshape(k_max, j_max, i_max, order='F').transpose(-1, 1, 0))\n",
    "\n",
    "    _, vert_arr, conn_arr, _ = grid.get_vtk_esg_geometry_data()\n",
    "    #vert_arr = np.asfortranarray(vert_arr)\n",
    "    conn_arr = conn_arr.astype('int64')\n",
    "    vol_active_cells = grid.get_bulk_volume().get_npvalues1d(activeonly = True ,  order = 'F')\n",
    "\n",
    "    #оцениваем качество сетки\n",
    "    grid.get_gridquality_properties()\n",
    "    df_grid = grid.get_dataframe(activeonly=True)\n",
    "    df_grid[['IX', 'JY', 'KZ']] = df_grid[['IX', 'JY', 'KZ']].astype(int)\n",
    "\n",
    "    #1. треугольные ячейки\n",
    "    idx_cells = df_grid[(df_grid['minangle_topbase']<1)|(df_grid['maxangle_topbase']>179)\n",
    "                           |(df_grid['minangle_topbase_proj']<1)|(df_grid['maxangle_topbase_proj']>179)\n",
    "                           |(df_grid['minangle_sides']<1)|(df_grid['maxangle_sides']>179)].index.tolist()\n",
    "    ijk_er = df_grid.loc[idx_cells][['IX', 'JY', 'KZ']].values\n",
    "    idx_err_triang = ijk_er[:,2]*i_max*j_max+ijk_er[:,1]*i_max +ijk_er[:,0]\n",
    "\n",
    "    #2. Вогнутые ячейки, если смотреть сверху.\n",
    "    # Ячейка является вогнутой, если один угол находится внутри треугольника, образованного другими углами сверху и/или основания.\n",
    "    # Проверяются только координаты X, Y\n",
    "    idx_cells = df_grid[(df_grid['concave_proj']>0)].index.tolist()\n",
    "    ijk_er = df_grid.loc[idx_cells][['IX', 'JY', 'KZ']].values\n",
    "    idx_err_concave_proj = ijk_er[:,2]*i_max*j_max+ijk_er[:,1]*i_max +ijk_er[:,0]\n",
    "\n",
    "    #3. схлопнутые по оси z ячейки\n",
    "    idx_cells = df_grid[df_grid['collapsed']> 0].index.tolist()\n",
    "    ijk_er = df_grid.loc[idx_cells][['IX', 'JY', 'KZ']].values\n",
    "    idx_err_collapsed = ijk_er[:,2]*i_max*j_max+ijk_er[:,1]*i_max +ijk_er[:,0]\n",
    "\n",
    "    #4. отрицательная толщина (по оси z считается)\n",
    "    idx_cells = df_grid[(df_grid['negative_thickness']>0)].index.tolist()\n",
    "    ijk_er = df_grid.loc[idx_cells][['IX', 'JY', 'KZ']].values\n",
    "    idx_err_negative_thickness = ijk_er[:,2]*i_max*j_max+ijk_er[:,1]*i_max +ijk_er[:,0]\n",
    "\n",
    "    return {\n",
    "        \"spec_grid\": [i_max, j_max, k_max],\n",
    "\n",
    "        'active_cells': grid.get_actnum_indices(order='F', inverse=False).tolist(),\n",
    "\n",
    "        'xyz_vertices': vert_arr.tolist(),\n",
    "        'connectivity_array_cell': conn_arr.tolist(),\n",
    "        'volumes_active_cells': vol_active_cells.tolist(),\n",
    "        'triangle_cells': idx_err_triang.tolist(),\n",
    "        'concave_proj_cells': idx_err_concave_proj.tolist(),\n",
    "        'collapsed_cells': idx_err_collapsed.tolist(),\n",
    "        'negative_thickness_cells': idx_err_negative_thickness.tolist()\n",
    "    }, errors\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:01.217174Z",
     "start_time": "2025-03-04T04:37:01.213186300Z"
    }
   },
   "id": "ec24118c24c6bda9",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_unique_coordinates(coord_list):\n",
    "    \"\"\"\n",
    "    Функция находит все неповторяющеся координаты по инлайнам и крослайнам\n",
    "    \"\"\"\n",
    "    x_set = set()\n",
    "    y_set = set()\n",
    "\n",
    "    for coord in coord_list:\n",
    "        x_set.add(coord['x'])\n",
    "        y_set.add(coord['y'])\n",
    "\n",
    "    x_unique = list(x_set)\n",
    "    y_unique = list(y_set)\n",
    "\n",
    "    return x_unique, y_unique\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:09.746009100Z",
     "start_time": "2025-03-04T04:37:09.720587700Z"
    }
   },
   "id": "8c38fddc6bee203c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_comment_lines(data, commenter='--') -> str:\n",
    "    data_lines = data.strip().split('\\n')\n",
    "    newdata = []\n",
    "    for line in data_lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        elif line.find(commenter) != -1:\n",
    "            newline = line[0:line.find(commenter)].strip()\n",
    "            if len(newline) == 0:\n",
    "                continue\n",
    "            newdata.append(newline)\n",
    "        else:\n",
    "            newdata.append(line)\n",
    "    return '\\n'.join(newdata)\n",
    "\n",
    "def find_key(file_path: str) -> [bool, str]:\n",
    "    with open(file_path, 'r') as f:\n",
    "        contents = f.read()\n",
    "        contents = remove_comment_lines(contents, commenter='--')\n",
    "        contents_in_block = contents.strip().split('/')\n",
    "        keys_contents_in_block = [x.split()[0] for x in contents_in_block if x]\n",
    "        NumKeywords = len(contents_in_block)\n",
    "        if NumKeywords == 0:\n",
    "            return False, \"\"\n",
    "        else:\n",
    "            return True, keys_contents_in_block\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:21.200002700Z",
     "start_time": "2025-03-04T04:37:21.181867900Z"
    }
   },
   "id": "52868504b7d242cb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show_graf(data1, data2, df):\n",
    "    \"\"\"\n",
    "    data1 - структурная карта кровли\n",
    "    data2 - структурная карта подошвы\n",
    "    df - датафрейм, полученный из грида, содержащий координаты [Х, У, нижняя область грида, верхняя область грида]\n",
    "    \"\"\"\n",
    "        \n",
    "    # Создание фигуры\n",
    "    fig = go.Figure()\n",
    "\n",
    "    x1 = [point['x'] for point in data1]\n",
    "    y1 = [point['y'] for point in data1]\n",
    "    z1 = [point['z'] for point in data1]\n",
    "        \n",
    "    x2 = [point['x'] for point in data2]\n",
    "    y2 = [point['y'] for point in data2]\n",
    "    z2 = [point['z'] for point in data2]\n",
    "     \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x1,\n",
    "        y=y1,\n",
    "        z=z1,\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, color='blue'),\n",
    "        name='Top_TWT'\n",
    "    ))\n",
    "        \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x2,\n",
    "        y=y2,\n",
    "        z=z2,\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, color='red'),\n",
    "        name='Bottom_TWT'\n",
    "    ))\n",
    "    \n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=df['x'],\n",
    "        y=df['y'],\n",
    "        z=df['z_min'],\n",
    "        mode='markers',\n",
    "        name='Нижняя граница Грида',\n",
    "        marker=dict(color='yellow', size=2)\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=df['x'],\n",
    "        y=df['y'],\n",
    "        z=df['z_max'],\n",
    "        mode='markers',\n",
    "        name='Верхняя граница Грида',\n",
    "        marker=dict(color='yellow', size=2)\n",
    "    ))\n",
    "    \n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Визуализация структурных карт и верхней и нижней областей грида',\n",
    "        width=800,  \n",
    "        height=600,  \n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Показать график\n",
    "    fig.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:26.231892100Z",
     "start_time": "2025-03-04T04:37:26.223831700Z"
    }
   },
   "id": "5bb1f3d1e828472c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def procent_vihoda (df1, df2, oblast):\n",
    "    \"\"\"\n",
    "    функция считает процент от количества точек df1, которые находятся выше области точек df2\n",
    "    :param df1: датафрейм структурной карты\n",
    "    :param df2: датафрейм верхней или нижней области грида\n",
    "    oblast: имя области грида, которе мы сравниваем \"z_max\" или \"z_min\"\n",
    "    :return: процент. \n",
    "    В случае нижней границы грида и карты подошвы полученный процент вычитается из 100\n",
    "    \"\"\"\n",
    "   \n",
    "   \n",
    "    # Интерполяция значений z из первой области на координаты второй области\n",
    "    z_interpolated = griddata(\n",
    "        (df1['x'], df1['y']), \n",
    "        df1['z'], \n",
    "        (df2['x'], df2['y']), \n",
    "        method='linear'\n",
    "    )\n",
    "    \n",
    "    # Сравнение значений z\n",
    "    # Убираем NaN значения, если интерполяция не смогла найти соответствие\n",
    "    valid_indices = ~np.isnan(z_interpolated)\n",
    "    above_count = (z_interpolated[valid_indices] > df2[oblast][valid_indices]).sum()\n",
    "    total_count = valid_indices.sum()\n",
    "    \n",
    "    # Вычисление процента точек первой области выше второй\n",
    "    if total_count > 0:\n",
    "        percentage_above = (above_count / total_count) * 100\n",
    "    else:\n",
    "        percentage_above = 0\n",
    "    \n",
    "    return round(percentage_above, 2) \n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:31.618799700Z",
     "start_time": "2025-03-04T04:37:31.606335600Z"
    }
   },
   "id": "49c0519897981f65",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_percentage(df1, df2, flag):\n",
    "    # Создание интерполятора\n",
    "    interpolator = NearestNDInterpolator((df1['x'], df1['y']), df1['z'])\n",
    "    \n",
    "    # Интерполяция значений z из df1 на координаты из df2\n",
    "    z_interpolated = interpolator(df2['x'], df2['y'])\n",
    "\n",
    "    # Создание ячеек между z_min и z_max\n",
    "    z_min = df2['z_min'].values\n",
    "    z_max = df2['z_max'].values\n",
    "    cell_height = (z_max - z_min) / res[0][\"spec_grid\"][2]  # Высота ячейки\n",
    "\n",
    "    # Подсчет количества ячеек\n",
    "    count_above = 0\n",
    "    total_cells = 0\n",
    "\n",
    "    for i in range(len(z_min)):\n",
    "        for j in range(res[0][\"spec_grid\"][2]+1):  # 48 ячеек\n",
    "            cell_top = z_min[i] + (j + 1) * cell_height[i]\n",
    "            cell_bottom = z_min[i] + j * cell_height[i]\n",
    "            if flag == 0:  # Процент ячеек выше области df1\n",
    "                if z_interpolated[i] < cell_bottom:\n",
    "                    count_above += 1\n",
    "            elif flag == 1:  # Процент ячеек ниже области df1\n",
    "                if z_interpolated[i] > cell_top:\n",
    "                    count_above += 1\n",
    "            total_cells += 1\n",
    "\n",
    "    # Вычисление процента\n",
    "    if total_cells > 0:\n",
    "        percentage = (count_above / total_cells) * 100\n",
    "    else:\n",
    "        percentage = 0.0\n",
    "\n",
    "    return round(percentage, 2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:37:36.583415300Z",
     "start_time": "2025-03-04T04:37:36.574936700Z"
    }
   },
   "id": "335c0f7c1ab23bc6",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TWT_Bottom = seismic_ascii_parser(r\"C:/HV/Seismic/datas/TWT_Bottom_U1.txt\")\n",
    "TWT_Top = seismic_ascii_parser(r\"C:/HV/Seismic/datas/TWT_Top_U1.txt\")\n",
    "res = cube_grid_parser(r\"C:/HV/Seismic/datas/grid\", [\"GRID.GRDECL\", \"GRID_ACTNUM.GRDECL\", \"GRID_COORD.GRDECL\", \"GRID_ZCORN.GRDECL\"])\n",
    "connectivity_array_cell = np.array(res[0][\"connectivity_array_cell\"], dtype=np.int64)  \n",
    "xyz_vertices = np.array(res[0][\"xyz_vertices\"])\n",
    "spec_grid = np.array(res[0][\"spec_grid\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:39:49.006516800Z",
     "start_time": "2025-03-04T04:39:20.325570100Z"
    }
   },
   "id": "b65d7351424287b0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#1.Вычисляем центры ячеек по оси z и строим каркасную сетку vtk\n",
    "z_center_cells = np.sum(xyz_vertices[connectivity_array_cell.reshape(-1,8),2], axis=1)/8\n",
    "vert_arr = xyz_vertices\n",
    "vtk_points = vtkPoints()\n",
    "vtk_points.SetData(numpy_to_vtk(vert_arr, deep=1))\n",
    "vtk_cell_array = vtkCellArray()\n",
    "vtk_cell_array.SetData(8, numpy_to_vtkIdTypeArray(connectivity_array_cell, deep=1))\n",
    "\n",
    "vtk_esgrid = vtkExplicitStructuredGrid()\n",
    "vtk_esgrid.SetDimensions(spec_grid+1)\n",
    "vtk_esgrid.SetPoints(vtk_points)\n",
    "vtk_esgrid.SetCells(vtk_cell_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:39:56.757977800Z",
     "start_time": "2025-03-04T04:39:56.552126300Z"
    }
   },
   "id": "97349792fd7554fe",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Создаем свой грид в виде двух областей [x, y, z_min, z_max] размерности 186х214 ячеек над кровлей и подошвой\n",
    "\"\"\"\n",
    "x_coords, y_coords = extract_unique_coordinates(TWT_Top)\n",
    "start_x = min(x_coords)\n",
    "stop_x = max(x_coords)\n",
    "start_y = min(y_coords)\n",
    "stop_y = max(y_coords)\n",
    "delta_x = (max(x_coords) - min(x_coords)) / 186\n",
    "delta_y = (max(y_coords) - min(y_coords)) / 214\n",
    "\n",
    "grid = []\n",
    "for i in range(186):\n",
    "    #grid.append([])\n",
    "    for j in range(214):\n",
    "        grid.append([start_x + i*delta_x, start_y + j*delta_y, -2350, -2260])\n",
    "\n",
    "df = pd.DataFrame(np.array(grid), columns=['x', 'y', 'z_min', 'z_max'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T05:00:53.605595300Z",
     "start_time": "2025-03-04T05:00:53.555721900Z"
    }
   },
   "id": "d54f3103ca5102f",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "show_graf(TWT_Top, TWT_Bottom, df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f0c30d28fead9d03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pr_top = procent_vihoda(pd.DataFrame(TWT_Top), df[['x', 'y', 'z_max']], 'z_max')\n",
    "pr_bot = procent_vihoda(pd.DataFrame(TWT_Bottom), df[['x', 'y', 'z_min']], 'z_min')\n",
    "\n",
    "if pr_top == 100:\n",
    "    print('Ни одна точка структурного каркаса не попадает в область грида. тест не пройден, т.к. все точки сруктурного каркаса кровли выше области Грида')\n",
    "if pr_top == 0:\n",
    "    print('Ни одна точка структурного каркаса не попадает в область грида. тест не пройден, т.к. все точки сруктурного каркаса подошвы ниже области Грида')\n",
    "\n",
    "pr_top_1 = calculate_percentage(pd.DataFrame(TWT_Top), df, 0)\n",
    "pr_bot_1 = calculate_percentage(pd.DataFrame(TWT_Bottom), df, 1)\n",
    "print(pr_top_1 + pr_bot_1, '% ячеек грида, выходят за пределы структурного каркаса')\n",
    "print('Пространство структурного каркаса и грида пересекаются на ', 100 - pr_top_1 - pr_bot_1, '% от объёма грида')\n",
    "  \n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-04T05:01:26.682178500Z"
    }
   },
   "id": "6b43eb1b07c7ca6f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Из-за слишком большого значеня точек у меня не досчитывается Грид. Мне нужно получить из него датафрейм с координатами и верхней и нижней границей\n",
    "\"\"\"\n",
    "\n",
    "# Извлекаем координаты и создаем датафрейм\n",
    "data = []\n",
    "for i in range(connectivity_array_cell.shape[0]):\n",
    "    cell_indices = connectivity_array_cell[i]\n",
    "    cell_vertices = xyz_vertices[cell_indices]\n",
    "    \n",
    "    z_min = np.min(cell_vertices[2])  # Минимальное значение z в ячейке\n",
    "    z_max = np.max(cell_vertices[2])  # Максимальное значение z в ячейке\n",
    "    x_center = np.mean(cell_vertices[0])  # Центр по x\n",
    "    y_center = np.mean(cell_vertices[1])  # Центр по y\n",
    "    \n",
    "    data.append({'x': x_center, 'y': y_center, 'z_min': z_min, 'z_max': z_max})\n",
    "df = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30650818306f8577"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc7eca829eea902"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0647536869bd811"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
